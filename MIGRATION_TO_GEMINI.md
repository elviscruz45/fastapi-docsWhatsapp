# Migraci√≥n a Google Gemini

Este documento explica los cambios realizados para migrar de OpenAI a Google Gemini.

## ‚úÖ Cambios realizados

### 1. Dependencias actualizadas

- ‚ùå Removido: `openai>=1.12.0`
- ‚úÖ Agregado: `google-generativeai>=0.3.0`

### 2. Configuraci√≥n actualizada

En `fastapi_docswhatsapp/config/settings.py`:

- ‚ùå Removido: `openai_api_key`, `openai_model`
- ‚úÖ Agregado: `gemini_api_key`, `gemini_model`

### 3. Archivo renombrado

- ‚ùå `openai_analyzer.py` ‚Üí ‚úÖ `gemini_analyzer.py`

### 4. Clase actualizada

- ‚ùå `OpenAIAnalyzer` ‚Üí ‚úÖ `GeminiAnalyzer`

### 5. Variables de entorno actualizadas

En `.env` y `.env.example`:

```env
# Antes (OpenAI)
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini

# Ahora (Gemini)
GEMINI_API_KEY=your-gemini-api-key-here
GEMINI_MODEL=gemini-1.5-flash
```

## üîß Configuraci√≥n requerida

### 1. Instalar nuevas dependencias

```bash
poetry install
# o
pip install google-generativeai>=0.3.0
```

### 2. Obtener API Key de Google Gemini

1. Ve a [Google AI Studio](https://aistudio.google.com/)
2. Inicia sesi√≥n con tu cuenta de Google
3. Haz clic en "Get API Key"
4. Crea un nuevo proyecto si es necesario
5. Copia tu API Key

### 3. Actualizar archivo .env

```env
GEMINI_API_KEY=tu_api_key_de_gemini_aqui
GEMINI_MODEL=gemini-1.5-flash
```

## üöÄ Ventajas de usar Gemini

- **Mayor l√≠mite de tokens**: 8000 tokens vs 4000 de OpenAI
- **Mejor an√°lisis multimodal**: Procesamiento mejorado de im√°genes
- **Costo menor**: M√°s econ√≥mico que GPT-4
- **Integraci√≥n nativa con Google**: Mejor ecosistema
- **Respuestas m√°s largas**: Permite an√°lisis m√°s detallados

## üìä Diferencias t√©cnicas

### Implementaci√≥n anterior (OpenAI)

```python
from openai import AsyncOpenAI

client = AsyncOpenAI(api_key=api_key)
response = await client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[...],
    temperature=0.7,
    max_tokens=3000
)
```

### Implementaci√≥n actual (Gemini)

```python
import google.generativeai as genai

genai.configure(api_key=api_key)
model = genai.GenerativeModel("gemini-1.5-flash")
response = await asyncio.to_thread(
    model.generate_content,
    prompt,
    generation_config=genai.types.GenerationConfig(
        temperature=0.7,
        max_output_tokens=4000,
    )
)
```

## üîç Validaci√≥n

Para verificar que la migraci√≥n funciona correctamente:

1. **Ejecutar la API**:

```bash
uvicorn main:app --reload
```

2. **Probar endpoint**:

```bash
curl -X GET "http://localhost:8000/health"
```

3. **Verificar documentaci√≥n**:

- Abrir: `http://localhost:8000/docs`
- Confirmar que aparece "Google Gemini" en la descripci√≥n

## ‚ö†Ô∏è Notas importantes

- **Formato de respuesta**: Gemini puede generar respuestas ligeramente diferentes a OpenAI
- **Rate limits**: Google Gemini tiene l√≠mites diferentes de velocidad
- **Compatibilidad**: El formato JSON de salida se mantiene igual
- **Fallback**: Se mantiene el sistema de an√°lisis de emergencia si falla la IA

## üÜò Soluci√≥n de problemas

### Error: "Import google.generativeai could not be resolved"

```bash
pip install google-generativeai
```

### Error: "API key not valid"

1. Verificar que la API key es correcta
2. Confirmar que el proyecto de Google AI Studio est√° habilitado
3. Revisar que no hay espacios extra en el archivo .env

### Error: "Model not found"

Verificar que el modelo especificado existe:

- `gemini-1.5-flash` (recomendado)
- `gemini-1.5-pro`
- `gemini-1.0-pro`
